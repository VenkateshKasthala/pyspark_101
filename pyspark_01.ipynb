{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing  SparkSession from the pyspark.sql module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/29 17:16:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/29 17:16:45 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MySparkApplication\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('/Users/kvenkateshrao/Downloads/Tableau Full course/Season.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames from Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"John\", 28), (\"Anna\", 23), (\"Mike\", 35)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "|Season_Id|Season_Year|Orange_Cap_Id|Purple_Cap_Id|Man_of_the_Series_Id|\n",
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "|        1|       2008|          100|          102|                  32|\n",
      "|        2|       2009|           18|           61|                  53|\n",
      "|        3|       2010|          133|          131|                 133|\n",
      "|        4|       2011|          162|          194|                 162|\n",
      "|        5|       2012|          162|          190|                 315|\n",
      "|        6|       2013|           19|           71|                  32|\n",
      "|        7|       2014|           46|          364|                 305|\n",
      "|        8|       2015|          187|           71|                 334|\n",
      "|        9|       2016|            8|          299|                   8|\n",
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "|Season_Id|Season_Year|Orange_Cap_Id|Purple_Cap_Id|Man_of_the_Series_Id|\n",
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "|1        |2008       |100          |102          |32                  |\n",
      "|2        |2009       |18           |61           |53                  |\n",
      "|3        |2010       |133          |131          |133                 |\n",
      "|4        |2011       |162          |194          |162                 |\n",
      "|5        |2012       |162          |190          |315                 |\n",
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(n=5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "|Season_Id|Season_Year|Orange_Cap_Id|Purple_Cap_Id|Man_of_the_Series_Id|\n",
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "|        1|       2008|          100|          102|                  32|\n",
      "|        2|       2009|           18|           61|                  53|\n",
      "|        3|       2010|          133|          131|                 133|\n",
      "|        4|       2011|          162|          194|                 162|\n",
      "|        5|       2012|          162|          190|                 315|\n",
      "+---------+-----------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema and Summary Information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Season_Id: integer (nullable = true)\n",
      " |-- Season_Year: integer (nullable = true)\n",
      " |-- Orange_Cap_Id: integer (nullable = true)\n",
      " |-- Purple_Cap_Id: integer (nullable = true)\n",
      " |-- Man_of_the_Series_Id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/29 17:31:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+--------------------+\n",
      "|summary|         Season_Id|       Season_Year|    Orange_Cap_Id|     Purple_Cap_Id|Man_of_the_Series_Id|\n",
      "+-------+------------------+------------------+-----------------+------------------+--------------------+\n",
      "|  count|                 9|                 9|                9|                 9|                   9|\n",
      "|   mean|               5.0|            2012.0|92.77777777777777|164.77777777777777|  152.66666666666666|\n",
      "| stddev|2.7386127875258306|2.7386127875258306|71.18774082975554|107.60782705939398|   133.6487934850143|\n",
      "|    min|                 1|              2008|                8|                61|                   8|\n",
      "|    max|                 9|              2016|              187|               364|                 334|\n",
      "+-------+------------------+------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
